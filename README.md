# ğŸ§  What is Backpropagation?

**Backpropagation** is the algorithm used to train neural networks by adjusting the weights to minimize the loss function. It's essentially how the model learns from its errors.

---

## ğŸ§¬ Steps in Backpropagation

Letâ€™s say you have a simple neural network with:
Inputs â†’ Hidden Layers â†’ Output

---

### ğŸ” 1. Forward Pass

- Inputs are passed through the network layer by layer.
- The model makes a prediction $\hat{y}$ (output).
- The **loss** is calculated between $\hat{y}$ and the true value $y$.

**Example (Binary Classification - Binary Crossentropy Loss):**

L(y, Å·) = -y * log(Å·) - (1 - y) * log(1 - Å·)

---

### ğŸ”„ 2. Compute Gradients (Backpropagation)

The loss is propagated **backwards** through the network using the **chain rule** of calculus.

For each weight $w$, compute:

âˆ‚L / âˆ‚w

This involves:

- Derivative of the loss w.r.t. output.
- Derivative of the **activation function** (like ReLU, Sigmoid, etc.).
- Derivative of the neuron's output w.r.t. its weights.

---

### ğŸ“‰ 3. Weight Update (Gradient Descent)

Update each weight using:

w := w - Î· * âˆ‚L/âˆ‚w

Where:

- $w$ is the weight
- $\eta$ is the **learning rate**
- $\frac{\partial \mathcal{L}}{\partial w}$ is the gradient of the loss w.r.t. the weight

---

### Given a 2-layer neural network with one nodes each:

#### Forward Pass:

Layer 1 (hidden):

â€ƒâ€ƒzâ‚ = Wâ‚x + bâ‚
  
â€ƒâ€ƒaâ‚ = g(zâ‚)
  
Layer 2 (output):

â€ƒâ€ƒzâ‚‚ = Wâ‚‚aâ‚ + bâ‚‚
  
â€ƒâ€ƒÅ· = F(zâ‚‚)
  
Loss:

â€ƒâ€ƒL(y, Å·)

#### Backpropagation:

Step 1: Compute the gradient of the loss w.r.t. prediction:

â€ƒâ€ƒâˆ‚L/âˆ‚Å·

Step 2: Compute gradient for second layer weights:

â€ƒâ€ƒâˆ‚L/âˆ‚Wâ‚‚ = âˆ‚L/âˆ‚Å· â‹… âˆ‚Å·/âˆ‚zâ‚‚ â‹… âˆ‚zâ‚‚/âˆ‚Wâ‚‚ = Î´â‚‚ â‹… aâ‚áµ€
  
â€ƒâ€ƒwhere Î´â‚‚ = âˆ‚L/âˆ‚Å· â‹… Fâ€²(zâ‚‚)
  
â€ƒâ€ƒUpdate: Wâ‚‚ := Wâ‚‚ - Î± â‹… Î´â‚‚ â‹… aâ‚áµ€

**Step 3: Compute gradient for first layer weights:**

â€ƒâ€ƒâˆ‚L/âˆ‚Wâ‚ = âˆ‚L/âˆ‚Å· â‹… âˆ‚Å·/âˆ‚zâ‚‚ â‹… âˆ‚zâ‚‚/âˆ‚aâ‚ â‹… âˆ‚aâ‚/âˆ‚zâ‚ â‹… âˆ‚zâ‚/âˆ‚Wâ‚ = Î´â‚ â‹… xáµ€
  
â€ƒâ€ƒwhere Î´â‚ = (Wâ‚‚áµ€ â‹… Î´â‚‚) âŠ™ gâ€²(zâ‚)
  
â€ƒâ€ƒUpdate: Wâ‚ := Wâ‚ - Î± â‹… Î´â‚ â‹… xáµ€

Final Update Rules:
â€ƒâ€ƒWâ‚‚ := Wâ‚‚ - Î± â‹… Î´â‚‚ â‹… aâ‚áµ€
â€ƒâ€ƒWâ‚ := Wâ‚ - Î± â‹… Î´â‚ â‹… xáµ€

Where âŠ™ denotes element-wise multiplication.

### Example:

  Setup:
  
  Input: x = 2
  
  True output: y = 1
  
  First layer:   a1 = m1 * x  
  
  Second layer:  y_hat = ReLU(a1 * m2) 
  
  Loss:          L = (1/2) * (y_hat - y)^2
  
  Goal: Update weights m1 and m2 using gradient descent.

### Step 1: Forward Pass:

    m1 = 3  
    m2 = 0.5  
    x = 2
  
  First layer output:
  
    a1 = m1 * x = 3 * 2 = 6
  
  Second layer output (ReLU):
  
    z2 = a1 * m2 = 6 * 0.5 = 3.0  
    y_hat = ReLU(3.0) = 3.0

### Step 2: Compute Loss

    L = (1/2) * (y_hat - y)^2  
      = (1/2) * (3.0 - 1)^2  
      = (1/2) * 4 = 2.0

### Step 3: Backward Pass (Gradient Calculation):

  Gradient w.r.t. m2:

    dL/dy_hat = y_hat - y = 3 - 1 = 2  
    dy_hat/dm2 = a1 = 6 (since ReLU is active)  
    => dL/dm2 = 2 * 6 = 12

Gradient w.r.t. m1:

    dL/dy_hat = 2  
    dy_hat/dz2 = 1 (ReLU is active)  
    dz2/da1 = m2 = 0.5  
    da1/dm1 = x = 2  
    => dL/dm1 = 2 * 1 * 0.5 * 2 = 2

### Step 4: Gradient Descent Update:

  Use learning rate Î± = 0.1

  Update m2:
  
    m2 = m2 - Î± * dL/dm2  
       = 0.5 - 0.1 * 12 = -0.7
  
  Update m1:
  
    m1 = m1 - Î± * dL/dm1  
       = 3 - 0.1 * 2 = 2.8

### Final Updated Weights:
    m1 = 2.8  
    m2 = -0.7

## ğŸ§  Backprop in the 2 Layers with Multiple Nodes:

#### ğŸ§  First Layer (Layer 1)
You have 10 nodes in the first layer:

aâ‚, aâ‚‚, ..., aâ‚â‚€

#### ğŸ§  Second Layer (Layer 2)
You also have 10 nodes in the second layer:

zâ‚, zâ‚‚, ..., zâ‚â‚€

Each node in Layer 2 is a linear combination of all the nodes in Layer 1. Specifically:

záµ¢ = wáµ¢â‚Â·aâ‚ + wáµ¢â‚‚Â·aâ‚‚ + ... + wáµ¢â‚â‚€Â·aâ‚â‚€ + báµ¢

Where:
- `wáµ¢â±¼` represents the weight from the `j`-th node in Layer 1 to the `i`-th node in Layer 2.
- `báµ¢` is the bias term for the `i`-th node in Layer 2.

#### ğŸ“Œ Example
For the first node in Layer 2:
zâ‚ = wâ‚â‚Â·aâ‚ + wâ‚â‚‚Â·aâ‚‚ + ... + wâ‚â‚â‚€Â·aâ‚â‚€ + bâ‚
zâ‚‚ = wâ‚‚â‚Â·aâ‚ + wâ‚‚â‚‚Â·aâ‚‚ + ... + wâ‚‚â‚â‚€Â·aâ‚â‚€ + bâ‚‚

And so on for all 10 nodes in Layer 2.

---

#### ğŸ“Š Matrix Representation

We can write the above equations compactly using matrices.

Let:
- `W(1)` be the weight matrix (size 10Ã—10).
- `A` be a column vector of Layer 1 activations (size 10Ã—1).
- `b(2)` be the bias vector for Layer 2 (size 10Ã—1).

Then:

Z = W(1) Â· A + b(2)


Where:

- `Z` is the output vector of Layer 2 (i.e., `[zâ‚, zâ‚‚, ..., zâ‚â‚€]áµ—`).

---

#### ğŸ”„ Backpropagation and Gradients

To update weights during training, we compute gradients with respect to each weight `wáµ¢â±¼`.

##### ğŸ§® Example: Gradient of Loss w.r.t. wâ‚â‚

Let `L` be the loss function.

âˆ‚L/âˆ‚wâ‚â‚ = âˆ‚L/âˆ‚zâ‚ Â· âˆ‚zâ‚/âˆ‚wâ‚â‚

Since:

zâ‚ = wâ‚â‚Â·aâ‚ + wâ‚â‚‚Â·aâ‚‚ + ... + wâ‚â‚â‚€Â·aâ‚â‚€

We get:

âˆ‚zâ‚/âˆ‚wâ‚â‚ = aâ‚

So:

âˆ‚L/âˆ‚wâ‚â‚ = Î´â‚ Â· aâ‚

Where:
- `Î´â‚ = âˆ‚L/âˆ‚zâ‚` is the error term for node 1 in Layer 2.

---

### âœï¸ Final Update Rule

After calculating all gradients, update each weight using:

wáµ¢â±¼ â† wáµ¢â±¼ âˆ’ Î± Â· âˆ‚L/âˆ‚wáµ¢â±¼

Where:
- `Î±` is the learning rate.



